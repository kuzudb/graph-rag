{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid RAG\n",
    "\n",
    "This notebook shows an example of the Hybrid RAG methodology, as per the BlackRock and Nvidia paper\n",
    "*[HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction](https://arxiv.org/abs/2408.04948)*\n",
    "from August 2024.\n",
    "\n",
    "This is similar to the intro Graph RAG pipeline, but with an important difference: the knowledge graph is constructed in *two* stages:\n",
    "- First, the text is preprocessed with an LLM that rewrites the text in simple sentences, so that the entities and relationships are more\n",
    "explicitly represented, and pronouns are replaced with the entities they refer to. This will help the extraction LLM in the second stage by providing a cleaner input.\n",
    "- Next, the entity and relationship extraction stage uses the preprocessed text to explicitly extract the nodes\n",
    "and edges that will represent the graph, as per a specified schema.\n",
    "\n",
    "The rest of the pipeline is similar to the intro RAG pipeline, where we also store the chunk embeddings of the original text in the vector store. At retrieval time, we retrieve from both the vector store and the graph store, and then combine the results using a Cohere reranker that provides the combined context to the generation LLM.\n",
    "\n",
    "The dataset used is about BlackRock Inc., the world's largest asset manager, and its founders and executives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "SEED = 37\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "COHERE_API_KEY = os.environ.get(\"COHERE_API_KEY\")\n",
    "\n",
    "assert OPENAI_API_KEY is not None, \"OPENAI_API_KEY is not set\"\n",
    "assert COHERE_API_KEY is not None, \"COHERE_API_KEY is not set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Set up the embedding model and LLM\n",
    "embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "extraction_llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.0, seed=SEED)\n",
    "generation_llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.3, seed=SEED)\n",
    "\n",
    "# Load the dataset on Larry Fink\n",
    "original_documents = SimpleDirectoryReader(\"../../data/blackrock\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Vector-only retrieval\n",
    "\n",
    "This stage demonstrates how to extract information into a vector database and store it in [LanceDB](https://lancedb.com/), an open source, embedded vector database. The aim of this stage is to use the vector database to answer the questions using vector-only retrieval, commonly known as \"naive RAG\" or traditional RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prrao/code/graph-rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# We'll use LanceDB to perform vector similarity search\n",
    "shutil.rmtree(\"./test_lancedb\", ignore_errors=True)\n",
    "\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
    "\n",
    "import openai\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-10-09T17:04:48Z WARN  lance::dataset] No existing dataset at /Users/prrao/code/graph-rag/src/02_hybrid_rag/test_lancedb/vectors.lance, it will be created\n"
     ]
    }
   ],
   "source": [
    "vector_store = LanceDBVectorStore(\n",
    "    uri=\"./test_lancedb\",\n",
    "    mode=\"overwrite\",\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    original_documents,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\", temperature=0.3, seed=SEED),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BlackRock was founded by Larry Fink and seven partners in 1988.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.llm = generation_llm\n",
    "\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=4)\n",
    "vector_query_engine = RetrieverQueryEngine(vector_retriever)\n",
    "\n",
    "response = vector_query_engine.query(\"Who founded BlackRock?\")\n",
    "str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larry Fink and Robert Kapito first met at First Boston, where Kapito worked in the Public Finance department.\n"
     ]
    }
   ],
   "source": [
    "response = vector_query_engine.query(\"Where did Larry Fink and Robert Kapito meet?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Graph-only retrieval\n",
    "\n",
    "Next, let's demonstrate how to extract information into a knowledge graph and store it in [Kùzu](https://kuzudb.com/), an open source, embedded graph database.\n",
    "The aim of this stage is to use the graph to answer the same questions as in Part 1, but using graph-only retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import List, Literal, Optional\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "from llama_index.graph_stores.kuzu import KuzuPropertyGraphStore\n",
    "\n",
    "import kuzu\n",
    "\n",
    "shutil.rmtree(\"test_kuzudb\", ignore_errors=True)\n",
    "db = kuzu.Database(\"test_kuzudb\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load processed documents\n",
    "\n",
    "For graph construction, we will load the preprocessed documents that were created by running the script `preprocess.py`, that rewrote the text in simple sentences, and replaced pronouns with the entities they refer to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_documents = SimpleDirectoryReader(\"../../data/blackrock/processed\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the allowed entities and relationships\n",
    "entities = Literal[\"PERSON\", \"CITY\", \"STATE\", \"UNIVERSITY\", \"ORGANIZATION\"]\n",
    "relations = Literal[\n",
    "    \"STUDIED_AT\",\n",
    "    \"IS_FOUNDER_OF\",\n",
    "    \"IS_CEO_OF\",\n",
    "    \"BORN_IN\",\n",
    "    \"IS_CITY_IN\",\n",
    "]\n",
    "\n",
    "# Define explicit relationship directions as a list of triples\n",
    "# The graph extraction process will be guided by this schema\n",
    "validation_schema = [\n",
    "    (\"PERSON\", \"STUDIED_AT\", \"UNIVERSITY\"),\n",
    "    (\"PERSON\", \"IS_CEO_OF\", \"ORGANIZATION\"),\n",
    "    (\"PERSON\", \"IS_FOUNDER_OF\", \"ORGANIZATION\"),\n",
    "    (\"PERSON\", \"BORN_IN\", \"CITY\"),\n",
    "    (\"CITY\", \"IS_CITY_IN\", \"STATE\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = KuzuPropertyGraphStore(\n",
    "    db,\n",
    "    has_structured_schema=True,\n",
    "    relationship_schema=validation_schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_path_extractor = SchemaLLMPathExtractor(\n",
    "    llm=extraction_llm,\n",
    "    possible_entities=entities,\n",
    "    possible_relations=relations,\n",
    "    kg_validation_schema=validation_schema,\n",
    "    strict=True,  # if false, will allow triples outside of the schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 3/3 [00:00<00:00, 2115.49it/s]\n",
      "Extracting paths from text with schema: 100%|██████████| 3/3 [00:10<00:00,  3.64s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set up the property graph index\n",
    "kg_index = PropertyGraphIndex.from_documents(\n",
    "    preprocessed_documents,\n",
    "    embed_model=embed_model,\n",
    "    kg_extractors=[schema_path_extractor],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the graph is created, we can explore it in [Kùzu Explorer](https://github.com/kuzudb/explorer), a web-base UI, by running a Docker container that pulls the latest image of Kùzu Explorer as follows:\n",
    "\n",
    "```bash\n",
    "docker run -p 8000:8000 \\\n",
    "           -v ./test_kuzudb:/database \\\n",
    "           -e MODE=READ_ONLY \\\n",
    "           --rm kuzudb/explorer:latest\n",
    "```\n",
    "\n",
    "Then, launch the UI and then visting http://localhost:8000/.\n",
    "\n",
    "The easiest way to see the entire graph is to use a Cypher query like `MATCH (a)-[b]->(c) RETURN * LIMIT 100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Larry Fink  \n",
      "2. Robert Kapito  \n",
      "3. Susan Wagner  \n"
     ]
    }
   ],
   "source": [
    "Settings.llm = generation_llm\n",
    "\n",
    "kg_retriever = kg_index.as_retriever()\n",
    "kg_query_engine = kg_index.as_query_engine(include_text=False)\n",
    "\n",
    "response = kg_query_engine.query(\"Who founded BlackRock? Return the names as a numbered list.\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The information provided does not specify where Larry Fink and Robert Kapito met.\n"
     ]
    }
   ],
   "source": [
    "response = kg_query_engine.query(\"Where did Larry Fink and Robert Kapito meet?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting the graph with external knowledge\n",
    "\n",
    "We know from a quick Google search that the given text documents don't provide the full picture of the founders of BlackRock. However, acquiring detailed textual information about entities in the data might not always be possible or feasible. In such cases, we can leverage external knowledge to add additional nodes to the graph to help with providing more relevant answers to the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.graph_stores.types import Relation, EntityNode\n",
    "\n",
    "# Say we have this knowledge obtained from other sources about additional founders of BlackRock\n",
    "additional_founders = [\n",
    "    \"Ben Golub\",\n",
    "    \"Barbara Novick\",\n",
    "    \"Ralph Schlosstein\",\n",
    "    \"Keith Anderson\",\n",
    "    \"Hugh Frater\",\n",
    "]\n",
    "\n",
    "# Add additional founder nodes of type PERSON to the graph store\n",
    "for founder in additional_founders:\n",
    "    graph_store.upsert_nodes(\n",
    "        [\n",
    "            EntityNode(label=\"PERSON\", name=founder),\n",
    "        ]\n",
    "    )\n",
    "    graph_store.upsert_relations(\n",
    "        [\n",
    "            Relation(\n",
    "                label=\"IS_FOUNDER_OF\",\n",
    "                source_id=founder,\n",
    "                target_id=\"BlackRock Inc.\",\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph looks something like this:\n",
    "\n",
    "![](../../assets/fink.png)\n",
    "\n",
    "The new nodes and relationships are now included in the graph, and are accessible to the graph query engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Larry Fink  \n",
      "2. Robert Kapito  \n",
      "3. Susan Wagner  \n",
      "4. Ben Golub  \n",
      "5. Barbara Novick  \n",
      "6. Ralph Schlosstein  \n",
      "7. Keith Anderson  \n",
      "8. Hugh Frater  \n"
     ]
    }
   ],
   "source": [
    "response = kg_query_engine.query(\"Who founded BlackRock? Return the names as a numbered list.\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text2Cypher pipeline that retrieves from the graph was able to provide the correct answer to the above question (8 co-founders, including Larry Fink himself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The information provided does not specify where Larry Fink and Robert Kapito met.\n"
     ]
    }
   ],
   "source": [
    "response = kg_query_engine.query(\"Where did Larry Fink and Robert Kapito meet?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways from graph-only retrieval\n",
    "\n",
    "It can be seen by inspecting the raw data that the LLM-extracted graph is incomplete. Once the right nodes/relationships are added to the graph, the quality of the graph-based retrieval improves significantly. This did require some manual curation, but we will demonstrate below that this process is worth it, by trying to answer the **same** questions using vector-only retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Combining graph and vector retrieval to build a Graph RAG system\n",
    "\n",
    "In this stage, we will demonstrate how to combine graph and vector retrieval and rerank the results in order to provide better context to the LLM prior to generating the response. We will use the afore-mentioned Kùzu and LanceDB databases to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.postprocessor.cohere_rerank.base import CohereRerank\n",
    "\n",
    "\n",
    "class CustomRerankerRetriever(BaseRetriever):\n",
    "    \"\"\"Custom retriever with cohere reranking.\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            kg_retriever,\n",
    "            vector_retriever,\n",
    "            cohere_api_key: Optional[str] = None,\n",
    "            cohere_top_n: int = 10,\n",
    "        ):\n",
    "        self._kg_retriever = kg_retriever\n",
    "        self._vector_retriever = vector_retriever\n",
    "        self._reranker = CohereRerank(\n",
    "            api_key=cohere_api_key, top_n=cohere_top_n\n",
    "        )\n",
    "\n",
    "    def _retrieve(self, query: str) -> List[NodeWithScore]:\n",
    "        \"\"\"Define custom retriever with reranking.\n",
    "\n",
    "        Could return `str`, `TextNode`, `NodeWithScore`, or a list of those.\n",
    "        \"\"\"\n",
    "        vector_retrieval_nodes = self._vector_retriever.retrieve(query)\n",
    "        kg_retrieval_nodes = self._kg_retriever.retrieve(query)\n",
    "        combined_nodes = vector_retrieval_nodes + kg_retrieval_nodes\n",
    "        reranked_nodes = self._reranker.postprocess_nodes(\n",
    "            combined_nodes,\n",
    "            query_str=str(query),\n",
    "        )\n",
    "        unique_nodes = {n.node_id: n for n in reranked_nodes}\n",
    "        return list(unique_nodes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/prrao/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "custom_reranker_retriever = CustomRerankerRetriever(\n",
    "    kg_retriever,\n",
    "    vector_retriever,\n",
    "    cohere_api_key=COHERE_API_KEY,\n",
    "    cohere_top_n=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Larry Fink  \n",
      "2. Susan Wagner  \n",
      "3. Ralph Schlosstein  \n",
      "4. Barbara Novick  \n",
      "5. Robert Kapito  \n",
      "6. Hugh Frater  \n",
      "7. Ben Golub  \n",
      "8. Keith Anderson  \n"
     ]
    }
   ],
   "source": [
    "# Set the LLM for generation in the CustomRerankerRetriever\n",
    "Settings.llm = generation_llm\n",
    "\n",
    "custom_reranker_query_engine = RetrieverQueryEngine(custom_reranker_retriever)\n",
    "\n",
    "response = custom_reranker_query_engine.query(\"Who founded BlackRock? Return the names as a numbered list.\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larry Fink and Robert Kapito met while working at First Boston.\n"
     ]
    }
   ],
   "source": [
    "response = custom_reranker_query_engine.query(\"Where did Larry Fink and Robert Kapito meet?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the retrieved nodes\n",
    "\n",
    "To inspect the reranked context, we can print the text of the nodes that were retrieved. It's clear that the reranker provides the most relevant context from *both* the vector store *and* the graph store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larry Fink is Founder, Chairman and CEO of BlackRock, Inc. He and seven partners founded BlackRock in 1988, and under his leadership, the firm has grown into a global leader in investment and technology solutions to help investors build better financial futures. Today, BlackRock is trusted to manage $10 trillion in assets, more than any other investment firm in the world.\n",
      "\n",
      "Mr. Fink was was born on November 2, 1952, in Van Nuys, California. He earned an MBA from UCLA in 1976 and a BA in political science, also from UCLA, in 1974.\n",
      "Susan Wagner is a cofounder and director of asset manager BlackRock, which she started with Larry Fink and others in 1988. She cofounded the company at age 26 and went on to serve as chief operating officer and vice chairman. Wagner oversaw BlackRock's 2009 merger with Barclay's Global Investors, which transformed the firm into the world's largest asset manager.\n",
      "\n",
      "Prior to founding BlackRock, Wagner worked as a vice president of the mortgage finance group at Lehman Brothers. She retired in 2012 but remains on BlackRock's board and also serves as a director of Apple and startups Color Health and Samsara.\n",
      "Ralph Schlosstein -> IS_FOUNDER_OF -> BlackRock Inc.\n",
      "Barbara Novick -> IS_FOUNDER_OF -> BlackRock Inc.\n",
      "Robert Kapito -> IS_FOUNDER_OF -> BlackRock Inc.\n",
      "Hugh Frater -> IS_FOUNDER_OF -> BlackRock Inc.\n",
      "Ben Golub -> IS_FOUNDER_OF -> BlackRock Inc.\n",
      "Susan Wagner -> IS_FOUNDER_OF -> BlackRock Inc.\n",
      "Keith Anderson -> IS_FOUNDER_OF -> BlackRock Inc.\n",
      "Robert Kapito is one of the most successful persons in the financial industry globally and well recognized as the co-founder and the President of BlackRock Inc. His career, full of innovation and top-class leadership, has changed and shaped the outlook of the world’s financial scene.\n",
      "\n",
      "Robert Kapito was born on February 8, 1957, in Monticello, New York.\n",
      "\n",
      "Mr. Kapito started his professional career in the First Boston in 1979 where he served in the Public Finance department. This work was the onset of his career, which was long and proved to be significant in finance. During his work at First Boston he first met Larry Fink, who would later be his partner at BlackRock.\n"
     ]
    }
   ],
   "source": [
    "nodes = custom_reranker_query_engine.retrieve(\"Who founded BlackRock? Return the names as a numbered list.\")\n",
    "for item in nodes:\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Kapito is one of the most successful persons in the financial industry globally and well recognized as the co-founder and the President of BlackRock Inc. His career, full of innovation and top-class leadership, has changed and shaped the outlook of the world’s financial scene.\n",
      "\n",
      "Robert Kapito was born on February 8, 1957, in Monticello, New York.\n",
      "\n",
      "Mr. Kapito started his professional career in the First Boston in 1979 where he served in the Public Finance department. This work was the onset of his career, which was long and proved to be significant in finance. During his work at First Boston he first met Larry Fink, who would later be his partner at BlackRock.\n",
      "Robert Kapito -> STUDIED_AT -> First Boston\n",
      "Larry Fink -> STUDIED_AT -> UCLA\n",
      "Robert Kapito -> IS_FOUNDER_OF -> BlackRock Inc.\n",
      "Robert Kapito -> BORN_IN -> Monticello\n",
      "Larry Fink -> BORN_IN -> Van Nuys\n",
      "Robert Kapito -> IS_CEO_OF -> BlackRock Inc.\n",
      "Robert Kapito -> IS_CEO_OF -> First Boston\n",
      "Larry Fink is Founder, Chairman and CEO of BlackRock, Inc. He and seven partners founded BlackRock in 1988, and under his leadership, the firm has grown into a global leader in investment and technology solutions to help investors build better financial futures. Today, BlackRock is trusted to manage $10 trillion in assets, more than any other investment firm in the world.\n",
      "\n",
      "Mr. Fink was was born on November 2, 1952, in Van Nuys, California. He earned an MBA from UCLA in 1976 and a BA in political science, also from UCLA, in 1974.\n",
      "Monticello -> IS_CITY_IN -> New York\n"
     ]
    }
   ],
   "source": [
    "nodes = custom_reranker_query_engine.retrieve(\"Where did Larry Fink and Robert Kapito meet?\")\n",
    "for item in nodes:\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "As can be seen from this demo, combining graph and vector retrieval can, on average, provide more accurate and contextually relevant answers to the questions. In certain cases, the vector retrieval can retrieve answers that are relevant through the fuzzy relationships that are implicitly modelled via the embeddings. In other cases, the graph retrieval can provide more relevant, complete answers, because it *explicitly* models the relationships between the entities in the text. It's important to note that the two types of retrievals can complement each other, rather than being in competition.\n",
    "\n",
    "By combining vector and graph retrieval and a reranker retriever that can leverage the context from both kinds of retrieval to provide the generation LLM with more relevant and accurate context, and thus a more relevant answer than if either retrieval method was used on its own.\n",
    "\n",
    "In practice, the Graph RAG system can be used to answer a wide range of questions, such as factual questions, definition questions, and reasoning questions. The key is to build a high-quality knowledge graph, and to combine it with vector search in a way that provides the most relevant and accurate answers to the questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
